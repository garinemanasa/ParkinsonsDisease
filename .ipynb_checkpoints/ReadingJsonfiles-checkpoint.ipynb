{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b9c14e-e19a-4ed6-bf25-123e5a71a65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Define the directories for different datasets\n",
    "\n",
    "dataset_dir = r\"C:\\Users\\garin\\Documents\\GitHub\\ParkinsonsDisease\"\n",
    "\n",
    "patients_dir = os.path.join(dataset_dir, 'pads-parkinsons-disease-smartwatch-dataset\\patients')\n",
    "\n",
    "Patients_csv = \"Patients.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b56d63e7-ca9c-4367-89fe-a9ad3aa2ba62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:17\u001b[1;36m\u001b[0m\n\u001b[1;33m    with open(Patients_csv, 'w', newline='', encoding='utf-8') as csvfile:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the extracted data\n",
    "data_list = []\n",
    "\n",
    "# Loop through each file in the folder and extract data\n",
    "for filename in os.listdir(patients_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(patients_dir, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            data_list.append(data)\n",
    "\n",
    "# Write the extracted data to a CSV file\n",
    "#csv_file_path = r\"C:\\Users\\garin\\Documents\\GitHub\\ParkinsonsDisease\\Patientsdata.csv\"\n",
    "#csv_file_path=Patientdata.csv\n",
    "\n",
    "\n",
    "     with open(Patients_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header (assuming all JSON files have the same structure)\n",
    "        if data_list:\n",
    "        header = data_list[0].keys()\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # Write the data\n",
    "          for data in data_list:\n",
    "                writer.writerow(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb196a64-7d2a-4733-8100-1c0972ed59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Define the directories for different datasets\n",
    "dataset_dir = r'C:\\Users\\garin\\OneDrive\\Numpy 2025\\Datathon feb2025\\pads-parkinsons-disease-smartwatch-dataset'\n",
    "patients_dir = r'C:\\Users\\garin\\OneDrive\\Numpy 2025\\Datathon feb2025\\pads-parkinsons-disease-smartwatch-dataset\\pads-parkinsons-disease-smartwatch-dataset\\patients'\n",
    "\n",
    "# Initialize a list to store the extracted data\n",
    "data_list = []\n",
    "\n",
    "# Loop through each file in the folder and extract data\n",
    "for filename in os.listdir(patients_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(patients_dir, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            data_list.append(data)\n",
    "\n",
    "# Write the extracted data to a CSV file\n",
    "csv_file_path = r'C:\\Users\\garin\\Documents\\GitHub\\ParkinsonsDisease\\Patients.csv'\n",
    "\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header (assuming all JSON files have the same structure)\n",
    "    if data_list:\n",
    "        header = data_list[0].keys()\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # Write the data\n",
    "        for data in data_list:\n",
    "            writer.writerow(data.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db10b7d8-af7b-4502-ba17-71efa78643eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 33\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m data_list:\n\u001b[1;32m---> 33\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow(data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData successfully written to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Write the extracted data to a CSV file\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_list:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m     25\u001b[0m         writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile)\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;66;03m# Write the header (assuming all JSON files have the same structure)\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Define directory path\n",
    "patients_dir = r\"C:/Users/garin/Documents/GitHub/ParkinsonsDisease/pads-parkinsons-disease-smartwatch-dataset/patients\"\n",
    "\n",
    "# Define CSV file path\n",
    "csv_file_path = r\"C:\\Users\\garin\\Documents\\GitHub\\ParkinsonsDisease\\PatientsData.csv\"\n",
    "\n",
    "# Initialize a list to store extracted data\n",
    "data_list = []\n",
    "\n",
    "# Loop through each JSON file in the folder and extract data\n",
    "for filename in os.listdir(patients_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(patients_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            data_list.append(data)\n",
    "\n",
    "# Write the extracted data to a CSV file\n",
    "if data_list:\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header (assuming all JSON files have the same structure)\n",
    "        header = data_list[0].keys()\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Write the data\n",
    "        for data in data_list:\n",
    "            writer.writerow(data.values())\n",
    "\n",
    "    print(f\"Data successfully written to {csv_file_path}\")\n",
    "else:\n",
    "    print(\"No JSON data found to write.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d72bffa-b500-4487-b610-08a1e10c483d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garin\\Documents\\GitHub\\ParkinsonsDisease\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Prints the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76aa9a02-7a96-45de-ae07-ab0b114f7413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae7feb4-2cb4-4035-9308-a85a16940f46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as questionnaire.csv\n"
     ]
    }
   ],
   "source": [
    "#Read json files from questionnaire folder and extract data to csv\n",
    "\n",
    "# Folder containing JSON files\n",
    "folder_pathq = r\"C:\\Users\\garin\\Documents\\GitHub\\ParkinsonsDisease\\pads-parkinsons-disease-smartwatch-dataset\"\n",
    "questionnaire_csv = \"questionnaire.csv\"\n",
    "# List to store extracted data\n",
    "data_list1 = []\n",
    "# Iterate through all JSON files in the folder\n",
    "for file_name in os.listdir(folder_pathq):\n",
    "    if file_name.endswith(\".json\"):  # Process only JSON files\n",
    "        file_path1 = os.path.join(folder_pathq, file_name)\n",
    "        # Open and read JSON file\n",
    "        with open(file_path1, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "            # Extract metadata\n",
    "            subject_id = data.get(\"subject_id\", \"\")\n",
    "            study_id = data.get(\"study_id\", \"\")\n",
    "            questionnaire_name = data.get(\"questionnaire_name\", \"\")\n",
    "            # Extract each item (question & response)\n",
    "            for item in data.get(\"item\", []):\n",
    "                row = {\n",
    "                    \"subject_id\": subject_id,\n",
    "                    \"study_id\": study_id,\n",
    "                    \"questionnaire_name\": questionnaire_name,\n",
    "                    \"link_id\": item.get(\"link_id\", \"\"),\n",
    "                    \"question_text\": item.get(\"text\", \"\"),\n",
    "                    \"answer\": item.get(\"answer\", \"\")\n",
    "                }\n",
    "                data_list1.append(row)\n",
    "# Convert list to DataFrame\n",
    "df = pd.DataFrame(data_list1)\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(questionnaire_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"CSV file saved as {questionnaire_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca06960-d379-4643-bcd8-7d73691e4bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
